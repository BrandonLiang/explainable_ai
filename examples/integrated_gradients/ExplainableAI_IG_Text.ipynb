{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vN4D_S3r4Uij"
   },
   "source": [
    "# Text model explanation using Integrated Gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8YefO7K8w1Tl"
   },
   "source": [
    "### Imports and installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "9u-KZTlpF2yA"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy             as np\n",
    "import tensorflow        as tf\n",
    "\n",
    "from tensorflow.keras.datasets      import imdb\n",
    "from tensorflow.keras.layers        import (Conv1D,\n",
    "                                            Dense,\n",
    "                                            Dropout,\n",
    "                                            Embedding,\n",
    "                                            GlobalMaxPooling1D,\n",
    "                                            Input)\n",
    "from tensorflow.keras.models        import Model\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.utils         import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "bB1hgm3Tf4AR"
   },
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B3y96jmseHYe",
    "outputId": "46b69ab3-28cf-485c-89a8-d99afc4a8f52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'explainable_ai'...\n",
      "remote: Enumerating objects: 18, done.\u001b[K\n",
      "remote: Counting objects: 100% (18/18), done.\u001b[K\n",
      "remote: Compressing objects: 100% (14/14), done.\u001b[K\n",
      "remote: Total 18 (delta 0), reused 18 (delta 0), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (18/18), done.\n"
     ]
    }
   ],
   "source": [
    "!rm -rf explainable_ai\n",
    "!git clone https://github.com/kartikparnami/explainable_ai.git\n",
    "from explainable_ai.integrated_gradients.ig_text import IntegratedGradientsText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XG-rv9NEw9tt"
   },
   "source": [
    "### Construct model and utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "jt4Vy4zsAynj"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE          = 256\n",
    "EMBEDDING_DIMS      = 50\n",
    "EPOCHS              = 5\n",
    "NUM_FILTERS         = 250\n",
    "HIDDEN_DIMS         = 250\n",
    "INTERNAL_BATCH_SIZE = 100\n",
    "KERNEL_SIZE         = 3\n",
    "MAX_FEATURES        = 10000\n",
    "MAX_LEN             = 100\n",
    "NB_SAMPLES          = 10\n",
    "N_STEPS             = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oAdDTPcCezX6",
    "outputId": "b79d61fb-7b80-4677-8720-e27e543cbf91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 2s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
      "1646592/1641221 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "def decode_sentence(x, reverse_index):\n",
    "    # the `-3` offset is due to the special tokens used by keras\n",
    "    # see https://stackoverflow.com/questions/42821330/restore-original-text-from-keras-s-imdb-dataset\n",
    "    return \" \".join([reverse_index.get(i - 3, 'UNK') for i in x])\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=MAX_FEATURES)\n",
    "\n",
    "# test_labels = y_test.copy()\n",
    "# train_labels = y_train.copy()\n",
    "y_train, y_test = to_categorical(y_train), to_categorical(y_test)\n",
    "x_train, x_test = sequence.pad_sequences(x_train, maxlen=MAX_LEN), sequence.pad_sequences(x_test, maxlen=MAX_LEN)\n",
    "index = imdb.get_word_index()\n",
    "reverse_index = {value: key for (key, value) in index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mF7BfwEHgC1T",
    "outputId": "74405776-036a-4fcd-8279-20669aebc77b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "98/98 [==============================] - 2s 18ms/step - loss: 0.5875 - accuracy: 0.6688 - val_loss: 0.4161 - val_accuracy: 0.8224\n",
      "Epoch 2/5\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 0.3174 - accuracy: 0.8643 - val_loss: 0.3533 - val_accuracy: 0.8504\n",
      "Epoch 3/5\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 0.2109 - accuracy: 0.9184 - val_loss: 0.3337 - val_accuracy: 0.8538\n",
      "Epoch 4/5\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 0.1380 - accuracy: 0.9517 - val_loss: 0.3534 - val_accuracy: 0.8438\n",
      "Epoch 5/5\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 0.0784 - accuracy: 0.9761 - val_loss: 0.3829 - val_accuracy: 0.8411\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f23c5f42588>"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = Input(shape=(MAX_LEN,), dtype='float32')\n",
    "embedded_sequences = Embedding(MAX_FEATURES, EMBEDDING_DIMS)(inputs)\n",
    "out = Conv1D(NUM_FILTERS,\n",
    "             KERNEL_SIZE,\n",
    "             padding='valid',\n",
    "             activation='relu',\n",
    "             strides=1)(embedded_sequences)\n",
    "out = Dropout(0.4)(out)\n",
    "out = GlobalMaxPooling1D()(out)\n",
    "out = Dense(HIDDEN_DIMS,\n",
    "            activation='relu')(out)\n",
    "out = Dropout(0.4)(out)\n",
    "outputs = Dense(2, activation='softmax')(out)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=EPOCHS,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o1s0uherxPmJ"
   },
   "source": [
    "### Integrated gradients text explanation and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "cmqA7HyqVnIv"
   },
   "outputs": [],
   "source": [
    "ig_explainer = IntegratedGradientsText(model,\n",
    "                                       layer=model.layers[1],\n",
    "                                       n_steps=N_STEPS,\n",
    "                                       internal_batch_size=INTERNAL_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "maUna98LxpNN"
   },
   "source": [
    "#### Positive prediction example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "id": "RR6XrrrLVrn1",
    "outputId": "7317583d-9efe-48ba-e540-1486b54c1a2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label =  1: Positive review\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<mark style=background-color:#f8f3f6>a </mark><mark style=background-color:#c0e593>powerful </mark><mark style=background-color:#faebf3>study </mark><mark style=background-color:#f9eff4>of </mark><mark style=background-color:#eef6e2>loneliness </mark><mark style=background-color:#f5f7f2>sexual </mark><mark style=background-color:#f9eef4>UNK </mark><mark style=background-color:#f2f6ec>and </mark><mark style=background-color:#f8f2f5>desperation </mark><mark style=background-color:#edf6df>be </mark><mark style=background-color:#bde38d>patient </mark><mark style=background-color:#f8f2f5>UNK </mark><mark style=background-color:#f5f7f2>up </mark><mark style=background-color:#f5f7f2>the </mark><mark style=background-color:#d2ecb0>atmosphere </mark><mark style=background-color:#f3f7ef>and </mark><mark style=background-color:#faebf3>pay </mark><mark style=background-color:#f7f7f6>attention </mark><mark style=background-color:#f7f7f6>to </mark><mark style=background-color:#edf6df>the </mark><mark style=background-color:#c4e699>wonderfully </mark><mark style=background-color:#f9eff4>written </mark><mark style=background-color:#f3bcdd>script </mark><mark style=background-color:#f4f7f0>br </mark><mark style=background-color:#f8f5f6>br </mark><mark style=background-color:#f4f7f0>i </mark><mark style=background-color:#ebf6dc>praise </mark><mark style=background-color:#fbe7f2>robert </mark><mark style=background-color:#f7f6f7>altman </mark><mark style=background-color:#f7f7f7>this </mark><mark style=background-color:#f5f7f3>is </mark><mark style=background-color:#f7f7f7>one </mark><mark style=background-color:#f8f5f6>of </mark><mark style=background-color:#f5f7f2>his </mark><mark style=background-color:#f8f2f5>many </mark><mark style=background-color:#f9eef4>films </mark><mark style=background-color:#edf6e1>that </mark><mark style=background-color:#c0e593>deals </mark><mark style=background-color:#f2f6ec>with </mark><mark style=background-color:#a1d26a>unconventional </mark><mark style=background-color:#276419>fascinating </mark><mark style=background-color:#faebf3>subject </mark><mark style=background-color:#d8efb9>matter </mark><mark style=background-color:#f5f7f3>this </mark><mark style=background-color:#f4f7f0>film </mark><mark style=background-color:#f6f7f5>is </mark><mark style=background-color:#f6f7f5>disturbing </mark><mark style=background-color:#f6f7f5>but </mark><mark style=background-color:#edf6e1>it's </mark><mark style=background-color:#faedf3>sincere </mark><mark style=background-color:#f5f7f2>and </mark><mark style=background-color:#eef6e2>it's </mark><mark style=background-color:#f0f6e7>sure </mark><mark style=background-color:#f7f6f7>to </mark><mark style=background-color:#f9eff4>UNK </mark><mark style=background-color:#f7f6f7>a </mark><mark style=background-color:#a1d26a>strong </mark><mark style=background-color:#cfebaa>emotional </mark><mark style=background-color:#fbd8eb>response </mark><mark style=background-color:#f7f6f7>from </mark><mark style=background-color:#eef6e2>the </mark><mark style=background-color:#fbe8f2>viewer </mark><mark style=background-color:#f8f3f6>if </mark><mark style=background-color:#ebf6db>you </mark><mark style=background-color:#f8f2f5>want </mark><mark style=background-color:#f6f7f5>to </mark><mark style=background-color:#f2f6ec>see </mark><mark style=background-color:#f7f7f6>an </mark><mark style=background-color:#83bf46>unusual </mark><mark style=background-color:#f3f7ef>film </mark><mark style=background-color:#f2f6ec>some </mark><mark style=background-color:#fce3f0>might </mark><mark style=background-color:#faebf3>even </mark><mark style=background-color:#f7f7f7>say </mark><mark style=background-color:#f1b5d9>bizarre </mark><mark style=background-color:#f8f5f6>this </mark><mark style=background-color:#f7f7f7>is </mark><mark style=background-color:#e9f5d8>worth </mark><mark style=background-color:#f5f7f2>the </mark><mark style=background-color:#f3f6ed>time </mark><mark style=background-color:#f6f7f5>br </mark><mark style=background-color:#f5f7f2>br </mark><mark style=background-color:#fbd8eb>unfortunately </mark><mark style=background-color:#edf6e1>it's </mark><mark style=background-color:#f7f7f6>very </mark><mark style=background-color:#f5f7f3>difficult </mark><mark style=background-color:#f3f6ed>to </mark><mark style=background-color:#f3f6ed>find </mark><mark style=background-color:#f3f6ed>in </mark><mark style=background-color:#fde2f0>video </mark><mark style=background-color:#fce3f0>stores </mark><mark style=background-color:#cdeaa7>you </mark><mark style=background-color:#e9f5d6>may </mark><mark style=background-color:#f3f7ef>have </mark><mark style=background-color:#f3f6ed>to </mark><mark style=background-color:#d4edb3>buy </mark><mark style=background-color:#f4f7f0>it </mark><mark style=background-color:#f9f0f5>off </mark><mark style=background-color:#f5f7f2>the </mark><mark style=background-color:#f2f6ec>internet </mark>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_sample = x_test[:NB_SAMPLES]\n",
    "predictions = model(x_test_sample).numpy().argmax(axis=1)\n",
    "attrs = ig_explainer.explain_instance(x_test_sample,\n",
    "                                      baselines=None,\n",
    "                                      target=predictions)\n",
    "\n",
    "idx_to_visualize = 1\n",
    "pred_dict = {1: 'Positive review', 0: 'Negative review'}\n",
    "print('Predicted label =  {}: {}'.format(predictions[idx_to_visualize], pred_dict[predictions[idx_to_visualize]]))\n",
    "words = decode_sentence(x_test_sample[idx_to_visualize], reverse_index).split()\n",
    "ig_explainer.visualize(attrs[idx_to_visualize], words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xox36PEJ8HsF"
   },
   "source": [
    "The most important features that contribute to the positive prediction as identified by the Integrated Gradients technique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "233d-i9vxvsn"
   },
   "source": [
    "#### Negative prediction example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "id": "gcr2XDHPxEq0",
    "outputId": "fac02769-c268-48e8-f9a6-f1820d96c54e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label =  1: Positive review\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<mark style=background-color:#f3f6ed>the </mark><mark style=background-color:#ebf6dc>height </mark><mark style=background-color:#f7f7f7>of </mark><mark style=background-color:#f6f7f5>that </mark><mark style=background-color:#faecf3>UNK </mark><mark style=background-color:#3d7f1e>country's </mark><mark style=background-color:#5ea02c>civil </mark><mark style=background-color:#f3f7ef>war </mark><mark style=background-color:#f3f6ed>it </mark><mark style=background-color:#f7f6f7>would </mark><mark style=background-color:#f7f7f6>be </mark><mark style=background-color:#eff6e5>easy </mark><mark style=background-color:#f5f7f3>to </mark><mark style=background-color:#f2f6ec>see </mark><mark style=background-color:#f8f5f6>this </mark><mark style=background-color:#f7f7f7>as </mark><mark style=background-color:#f7f6f7>a </mark><mark style=background-color:#f8f5f6>UNK </mark><mark style=background-color:#f8f3f6>about </mark><mark style=background-color:#f9f1f5>those </mark><mark style=background-color:#ebf6db>events </mark><mark style=background-color:#f8f2f5>UNK </mark><mark style=background-color:#ebf6dc>may </mark><mark style=background-color:#f3f7ef>or </mark><mark style=background-color:#eff6e5>may </mark><mark style=background-color:#f7f7f7>not </mark><mark style=background-color:#f6f7f5>have </mark><mark style=background-color:#f9eef4>had </mark><mark style=background-color:#f8f4f6>UNK </mark><mark style=background-color:#faebf3>turmoil </mark><mark style=background-color:#f3f6ed>in </mark><mark style=background-color:#eaf5d9>mind </mark><mark style=background-color:#f2f6ec>when </mark><mark style=background-color:#f1f6ea>he </mark><mark style=background-color:#f7f7f7>made </mark><mark style=background-color:#f8f4f6>UNK </mark><mark style=background-color:#f7f7f7>but </mark><mark style=background-color:#f9f1f5>whatever </mark><mark style=background-color:#f9f0f5>UNK </mark><mark style=background-color:#f2f6ec>his </mark><mark style=background-color:#e9f5d6>choice </mark><mark style=background-color:#f7f7f7>of </mark><mark style=background-color:#fde1ef>material </mark><mark style=background-color:#f4f7f0>the </mark><mark style=background-color:#f4f7f0>film </mark><mark style=background-color:#dff2c4>stands </mark><mark style=background-color:#f3f6ed>as </mark><mark style=background-color:#f7f6f7>a </mark><mark style=background-color:#f8f3f6>UNK </mark><mark style=background-color:#ddf1c1>tale </mark><mark style=background-color:#f7f7f7>of </mark><mark style=background-color:#f5f7f3>universal </mark><mark style=background-color:#f9f1f5>UNK </mark><mark style=background-color:#f9f1f5>UNK </mark><mark style=background-color:#f8f2f5>could </mark><mark style=background-color:#f5f7f3>be </mark><mark style=background-color:#eff6e5>the </mark><mark style=background-color:#f6f7f5>soviet </mark><mark style=background-color:#e1f3c7>union </mark><mark style=background-color:#276419>italy </mark><mark style=background-color:#a1d26a>germany </mark><mark style=background-color:#eff6e4>or </mark><mark style=background-color:#cfebaa>japan </mark><mark style=background-color:#f5f7f2>in </mark><mark style=background-color:#f1f6ea>the </mark><mark style=background-color:#f9d3e8>1930s </mark><mark style=background-color:#f2f6ec>or </mark><mark style=background-color:#f8f2f5>any </mark><mark style=background-color:#f1f6ea>country </mark><mark style=background-color:#f7f6f7>of </mark><mark style=background-color:#f8f4f6>any </mark><mark style=background-color:#f5f7f3>era </mark><mark style=background-color:#eff6e4>that </mark><mark style=background-color:#d6eeb6>lets </mark><mark style=background-color:#f5f7f3>its </mark><mark style=background-color:#c0e593>guard </mark><mark style=background-color:#f4f7f0>down </mark><mark style=background-color:#f4f7f0>and </mark><mark style=background-color:#f7f7f7>is </mark><mark style=background-color:#f3f6ed>overwhelmed </mark><mark style=background-color:#edf6e1>by </mark><mark style=background-color:#f9f1f5>UNK </mark><mark style=background-color:#f3f7ef>it's </mark><mark style=background-color:#f7f7f7>a </mark><mark style=background-color:#bbe28a>fascinating </mark><mark style=background-color:#f7f7f6>film </mark><mark style=background-color:#f9eef4>even </mark><mark style=background-color:#f7f7f7>a </mark><mark style=background-color:#f0f6e7>charming </mark><mark style=background-color:#f5f7f3>one </mark><mark style=background-color:#f4f7f0>in </mark><mark style=background-color:#f5f7f3>its </mark><mark style=background-color:#edf6df>macabre </mark><mark style=background-color:#f7f7f7>way </mark><mark style=background-color:#f5f7f2>but </mark><mark style=background-color:#f7f7f7>its </mark><mark style=background-color:#ddf1c1>message </mark><mark style=background-color:#f6f7f5>is </mark><mark style=background-color:#f8f5f6>no </mark><mark style=background-color:#faecf3>joke </mark>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_to_visualize = 2\n",
    "pred_dict = {1: 'Positive review', 0: 'Negative review'}\n",
    "print('Predicted label =  {}: {}'.format(predictions[idx_to_visualize], pred_dict[predictions[idx_to_visualize]]))\n",
    "words = decode_sentence(x_test_sample[idx_to_visualize], reverse_index).split()\n",
    "ig_explainer.visualize(attrs[idx_to_visualize], words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MhHTImGu8LFI"
   },
   "source": [
    "The most important features that contribute to the negative prediction as identified by the Integrated Gradients technique"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ExplainableAI-IG-Text.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
